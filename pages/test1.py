import re
from collections import Counter

import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

# =========================================
# Education(ì‚¬ë²”) E-items (E1~E4)
# - E1~E3: ë³µìˆ˜ì„ íƒ(ì˜µì…˜í˜•)
# - E4: ì£¼ê´€ì‹
# - í™”ë©´ì—ëŠ” [ ] í‚¤ì›Œë“œ ì¤‘ì‹¬ + "E1~E4" í•¨ê»˜ í‘œê¸°
# =========================================
st.set_page_config(page_title="Education E-items (E1â€“E4)", layout="wide")

# âœ… ì‚¬ë²” ë°ì´í„° CSV raw URLë¡œ ë°”ê¾¸ì„¸ìš”
CSV_URL_EDU = "https://raw.githubusercontent.com/MK316/camp26/refs/heads/main/data/Edu-essay123.csv"

# âœ… ë©”íƒ€ ì»¬ëŸ¼
META_COLS = ["Academic_Field", "Year_Level", "Year_Original"]


# âœ… ì›ë³¸ ì»¬ëŸ¼ëª…ì´ ê¸¸ì–´ì„œ, ì‹¤ì œ íŒŒì¼ì˜ ì»¬ëŸ¼ëª…ê³¼ ì •í™•íˆ ë§¤ì¹­í•´ì•¼ í•©ë‹ˆë‹¤.
# ì•„ë˜ 4ê°œëŠ” "CSVì— ìˆëŠ” ì‹¤ì œ ì»¬ëŸ¼ëª…" ê·¸ëŒ€ë¡œ ë„£ì–´ì£¼ì„¸ìš”.
COL_E1_SRC = """1. [êµìœ¡ê³¼ì •Â·ì •ì±… ê°œì„  ìš”êµ¬] 
ë¯¸ë˜êµì‚¬ì˜ ë””ì§€í„¸Â·AI í™œìš© ì—­ëŸ‰ ê°•í™”ë¥¼ ìœ„í•´ ëŒ€í•™ êµìœ¡ê³¼ì •ì—ì„œ ê°€ì¥ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ì§€ì›ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?
(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)"""
COL_E2_SRC = """2. [ì •ì„œì  ë¶€ë‹´ê°ì˜ ì›ì¸] 
ë””ì§€í„¸Â·AI ê´€ë ¨ í•™ìŠµì—ì„œ ë¶€ë‹´ê°ì´ë‚˜ ì–´ë ¤ì›€ì„ ëŠë¼ëŠ” ì£¼ëœ ì´ìœ ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?
(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)"""
COL_E3_SRC = """3. [í•™ìŠµ ë‚´ìš© ì„ í˜¸] 
ëŒ€í•™ì—ì„œ ë””ì§€í„¸Â·AI ê´€ë ¨ ìˆ˜ì—…ì´ ê°œì„¤ëœë‹¤ë©´, ê°€ì¥ ë°°ìš°ê³  ì‹¶ì€ ë‚´ìš©ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?
(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)"""
COL_E4_SRC = """4. [ì£¼ê´€ì‹: ììœ ë¡­ê²Œ ê¸°ìˆ ] 

ë””ì§€í„¸Â·AI ë¬¸í•´ë ¥ ê°•í™”ë¥¼ ìœ„í•´ ëŒ€í•™ ì°¨ì›ì—ì„œ í•™ìƒë“¤ì—ê²Œ ìš°ì„ ì ìœ¼ë¡œ ì œê³µí•´ì•¼ í•  í•µì‹¬ ìš”ì†Œë‚˜ í‚¤ì›Œë“œëŠ” ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?"""

# âœ… ì•± ë‚´ë¶€ì—ì„œëŠ” ì§§ì€ í‚¤ë¡œ ë‹¤ë£¹ë‹ˆë‹¤.
COL_E1 = "E1"
COL_E2 = "E2"
COL_E3 = "E3"
COL_E4 = "E4"

COL_MAP = {
    COL_E1_SRC: COL_E1,
    COL_E2_SRC: COL_E2,
    COL_E3_SRC: COL_E3,
    COL_E4_SRC: COL_E4,
}

# âœ… í™”ë©´ í‘œì‹œ ë¼ë²¨: "E1 ~ + [í‚¤ì›Œë“œ]" í˜•íƒœ
DISPLAY_LABELS = {
    COL_E1: "E1. [êµìœ¡ê³¼ì •Â·ì •ì±… ê°œì„  ìš”êµ¬]",
    COL_E2: "E2. [ì •ì„œì  ë¶€ë‹´ê°ì˜ ì›ì¸]",
    COL_E3: "E3. [í•™ìŠµ ë‚´ìš© ì„ í˜¸]",
    COL_E4: "E4. [ì£¼ê´€ì‹: ììœ ë¡­ê²Œ ê¸°ìˆ ]",
    "Academic_Field": "í•™ë¬¸ ë¶„ì•¼ (Academic_Field)",
    "Year_Level": "í•™ë…„ (Year_Level)",
}

# =========================================
# (ì„ íƒ) ì˜µì…˜ ëª©ë¡ì„ ê³ ì •í•˜ê³  ì‹¶ë‹¤ë©´ ì—¬ê¸°ì— ë„£ìœ¼ì„¸ìš”.
# ì—†ìœ¼ë©´ ë°ì´í„°ì—ì„œ ë‚˜ì˜¨ ì„ íƒì§€ë¡œ ì§‘ê³„(ê¶Œì¥: ìš°ì„ ì€ ìë™).
# =========================================
E1_OPTIONS = None  # ì˜ˆ: ["ì˜µì…˜1", "ì˜µì…˜2", ...]
E2_OPTIONS = None
E3_OPTIONS = None

OPTIONS_MAP = {
    COL_E1: E1_OPTIONS,
    COL_E2: E2_OPTIONS,
    COL_E3: E3_OPTIONS,
}

# =========================================
# Helpers
# =========================================
@st.cache_data(show_spinner=False)
def load_data(url: str) -> pd.DataFrame:
    try:
        df = pd.read_csv(url, encoding="utf-8")
    except UnicodeDecodeError:
        df = pd.read_csv(url, encoding="cp949")

    # ê³µë°± ì œê±°
    for c in df.columns:
        if df[c].dtype == object:
            df[c] = df[c].astype(str).str.strip()

    # ê¸´ ì»¬ëŸ¼ëª…ì„ E1~E4ë¡œ rename
    missing_src = [c for c in COL_MAP.keys() if c not in df.columns]
    if missing_src:
        st.error("CSV ì»¬ëŸ¼ëª…ì´ ì½”ë“œì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì•„ë˜ ì»¬ëŸ¼ì´ CSVì— ì—†ìŠµë‹ˆë‹¤:\n\n- " + "\n- ".join(missing_src))
        st.stop()

    df = df.rename(columns=COL_MAP)

    # ë©”íƒ€ ì»¬ëŸ¼ í™•ì¸
    for c in META_COLS:
        if c not in df.columns:
            st.error(f"CSVì— ë©”íƒ€ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {c}")
            st.stop()

    return df


def clean_text(s: str) -> str:
    if not isinstance(s, str):
        return ""
    return re.sub(r"\s+", " ", s).strip()


def is_no_response(text: str) -> bool:
    t = clean_text(str(text)).lower()
    if t in {"", "nan", "none"}:
        return True
    return t in {"no response", "noresponse", "n/a", "na"}


def split_multiselect(text: str) -> list[str]:
    """
    ë³µìˆ˜ì„ íƒ ì‘ë‹µ íŒŒì‹± (êµ¬ê¸€í¼ CSVì—ì„œ í”í•œ íŒ¨í„´)
    - êµ¬ë¶„ì: ; , / | ì¤„ë°”ê¿ˆ
    """
    t = clean_text(text)
    if not t or is_no_response(t):
        return []
    t = t.replace("\n", ";").replace("â€¢", ";")
    parts = re.split(r"[;,/|]+", t)
    return [p.strip() for p in parts if p.strip()]


def multiselect_summary(df: pd.DataFrame, col: str, option_order: list[str] | None) -> tuple[pd.DataFrame, int]:
    base = df[[col]].copy()
    base["__rid__"] = base.index
    base["choices"] = base[col].apply(split_multiselect)

    n_resp = int((base["choices"].apply(len) > 0).sum())
    if n_resp == 0:
        out0 = pd.DataFrame({"ì˜µì…˜": (option_order or []), "ì‘ë‹µììˆ˜": 0, "ì‘ë‹µìë¹„ìœ¨(%)": 0.0})
        return out0, 0

    ex = base.explode("choices").dropna(subset=["choices"])
    ex["choices"] = ex["choices"].astype(str).str.strip()
    ex = ex[ex["choices"] != ""]

    # ì˜µì…˜ ëª©ë¡ ê³ ì •ì´ ìˆìœ¼ë©´ ì˜µì…˜ ì™¸ëŠ” 'ê¸°íƒ€'ë¡œ í¡ìˆ˜(ë‹¨, ê¸°íƒ€ê°€ ì—†ìœ¼ë©´ 'ê¸°íƒ€'ë¥¼ ì¶”ê°€)
    if option_order:
        allowed = set(option_order)
        if "ê¸°íƒ€" in allowed:
            ex.loc[~ex["choices"].isin(allowed), "choices"] = "ê¸°íƒ€"
        else:
            ex.loc[~ex["choices"].isin(allowed), "choices"] = "ê¸°íƒ€"
            option_order = option_order + ["ê¸°íƒ€"]

    grp = ex.drop_duplicates(subset=["__rid__", "choices"]).groupby("choices")["__rid__"].nunique()
    out = pd.DataFrame({"ì˜µì…˜": option_order or sorted(grp.index.tolist())})
    out["ì‘ë‹µììˆ˜"] = out["ì˜µì…˜"].map(grp).fillna(0).astype(int)
    out["ì‘ë‹µìë¹„ìœ¨(%)"] = (out["ì‘ë‹µììˆ˜"] / n_resp * 100).round(2)

    # âœ… ë§ì€ ë¹ˆë„ ë¨¼ì € ë³´ì´ë„ë¡
    out = out.sort_values(["ì‘ë‹µììˆ˜", "ì˜µì…˜"], ascending=[False, True]).reset_index(drop=True)
    return out, n_resp


def tokenize_ko_basic(text: str, stop: set[str]) -> list[str]:
    t = re.sub(r"[^0-9A-Za-zê°€-í£\s]", " ", str(text))
    t = re.sub(r"\s+", " ", t).strip()
    if not t:
        return []
    toks = []
    for w in t.split(" "):
        if len(w) < 2:
            continue
        if w in stop:
            continue
        toks.append(w)
    return toks


# =========================================
# UI
# =========================================
st.markdown("### ğŸ§© ì‚¬ë²”(Education) ì˜ì—­: E1â€“E4")
st.caption("E1â€“E3: ë³µìˆ˜ì„ íƒ(ì‘ë‹µì ê¸°ì¤€ %), E4: ì£¼ê´€ì‹(í‚¤ì›Œë“œ/ê·¸ë£¹ ë¹„êµ/ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬ + ì›Œë“œí´ë¼ìš°ë“œ(ê°€ëŠ¥ ì‹œ))")

df = load_data(CSV_URL_EDU)

with st.sidebar:
    st.header("í•„í„° (Filters)")

    all_af = sorted(df["Academic_Field"].dropna().astype(str).unique().tolist())
    af = st.multiselect("í•™ë¬¸ ë¶„ì•¼ (Academic_Field)", all_af, default=all_af)

    all_yl = sorted(df["Year_Level"].dropna().astype(str).unique().tolist())
    yl = st.multiselect("í•™ë…„ (Year_Level)", all_yl, default=all_yl)

    all_yo = sorted(df["Year_Original"].dropna().astype(str).unique().tolist())
    yo = st.multiselect("ì› í•™ë…„ í‘œê¸° (Year_Original)", all_yo, default=all_yo)

    st.divider()
    palette = st.selectbox(
        "ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (Bar ê³µí†µ)",
        ["Plotly", "D3", "G10", "T10", "Alphabet", "Dark24", "Set2", "Pastel"],
        index=0,
    )
    show_raw = st.checkbox("ì›ìë£Œ ì¼ë¶€ ë³´ê¸°", value=False)

fdf = df[
    df["Academic_Field"].isin(af) &
    df["Year_Level"].isin(yl) &
    df["Year_Original"].isin(yo)
].copy()


c1, c2, c3 = st.columns(3)
c1.metric("í‘œë³¸ ìˆ˜ (í˜„ì¬ í•„í„° N)", f"{len(fdf):,}")
c2.metric("ì„ íƒ Academic_Field ìˆ˜", f"{len(af):,}")
c3.metric("ì„ íƒ Year_Level ìˆ˜", f"{len(yl):,}")

if show_raw:
    st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    show_cols = META_COLS + [COL_E1, COL_E2, COL_E3, COL_E4]
    st.dataframe(fdf[show_cols].rename(columns=DISPLAY_LABELS).head(30), use_container_width=True)

tab1, tab2, tab3, tab4 = st.tabs([
    DISPLAY_LABELS[COL_E1],
    DISPLAY_LABELS[COL_E2],
    DISPLAY_LABELS[COL_E3],
    DISPLAY_LABELS[COL_E4],
])

# íŒ”ë ˆíŠ¸ -> ìƒ‰ìƒ ì‹œí€€ìŠ¤
color_seq = getattr(px.colors.qualitative, palette, px.colors.qualitative.Plotly)


def render_multi(col: str, option_order: list[str] | None):
    st.markdown(f"#### {DISPLAY_LABELS.get(col, col)}")
    st.caption("ë³µìˆ˜ì„ íƒ ë¬¸í•­ì…ë‹ˆë‹¤. ê·¸ë˜í”„ëŠ” â€˜ì‘ë‹µì ê¸°ì¤€ ë¹„ìœ¨(%)â€™ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")

    summ, n_resp = multiselect_summary(fdf, col, option_order)
    st.metric("í•´ë‹¹ ë¬¸í•­ ì‘ë‹µì ìˆ˜ (N)", f"{n_resp:,}")

    if n_resp == 0:
        st.info("í˜„ì¬ í•„í„° ì¡°ê±´ì—ì„œ ìœ íš¨ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # âœ… í•­ëª©ë³„ ë‹¤ë¥¸ ìƒ‰ + íŒ”ë ˆíŠ¸ ì ìš©
    opts = summ["ì˜µì…˜"].tolist()
    cmap = {opt: color_seq[i % len(color_seq)] for i, opt in enumerate(opts)}

    fig = px.bar(
        summ.sort_values("ì‘ë‹µìë¹„ìœ¨(%)", ascending=True),  # ê°€ë¡œë§‰ëŒ€ì—ì„œ ìœ„ìª½ì— í° ê°’
        x="ì‘ë‹µìë¹„ìœ¨(%)",
        y="ì˜µì…˜",
        orientation="h",
        text="ì‘ë‹µìë¹„ìœ¨(%)",
        color="ì˜µì…˜",
        color_discrete_map=cmap,
        title="ì„ íƒ ë¹„ìœ¨ (ì‘ë‹µì ê¸°ì¤€ %)"
    )
    fig.update_traces(texttemplate="%{text:.1f}%", textposition="outside", cliponaxis=False)
    fig.update_layout(
        height=560,
        showlegend=False,
        margin=dict(l=10, r=10, t=60, b=10),
        xaxis_title="ì‘ë‹µì ë¹„ìœ¨(%)",
        yaxis_title=""
    )
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("ì˜µì…˜ë³„ ë¹ˆë„í‘œ")
    st.dataframe(summ, use_container_width=True, hide_index=True)


with tab1:
    render_multi(COL_E1, OPTIONS_MAP[COL_E1])

with tab2:
    render_multi(COL_E2, OPTIONS_MAP[COL_E2])

with tab3:
    render_multi(COL_E3, OPTIONS_MAP[COL_E3])

with tab4:
    st.markdown(f"#### {DISPLAY_LABELS.get(COL_E4, COL_E4)}")
    st.caption("ì£¼ê´€ì‹ ë¬¸í•­ì…ë‹ˆë‹¤. 'No Response'ëŠ” ì œì™¸ë©ë‹ˆë‹¤. ì•„ë˜ëŠ” í‚¤ì›Œë“œ ë¹ˆë„, ê·¸ë£¹ë³„ ë¹„êµ, ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬, ì›Œë“œí´ë¼ìš°ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.")

    open_s = fdf[COL_E4].astype(str).map(clean_text)
    open_s = open_s[(open_s != "") & (~open_s.map(is_no_response))]

    st.metric("ì£¼ê´€ì‹ ì‘ë‹µ ìˆ˜ (N)", f"{len(open_s):,}")
    if open_s.empty:
        st.warning("í˜„ì¬ í•„í„° ì¡°ê±´ì—ì„œ E4 ì£¼ê´€ì‹ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # ---- ê¸°ë³¸ í† í°/ë¶ˆìš©ì–´ ----
    STOP = {
        "ê·¸ë¦¬ê³ ","í•˜ì§€ë§Œ","ë˜í•œ","ê·¸ë˜ì„œ","ë•Œë¬¸","ì •ë„","ê°™ì•„ìš”","í•©ë‹ˆë‹¤","í–ˆë‹¤","í•˜ëŠ”","ì—ì„œ","ìœ¼ë¡œ","ì—ê²Œ",
        "ê²ƒ","ìˆ˜","ë“±","ì¢€","ë”","ì œ","ì €","ìš°ë¦¬","ë„ˆë¬´","ì •ë§","ìˆë‹¤","ì—†ë‹¤","ì´ë‹¤","ë˜ë‹¤","ìˆëŠ”",
        "í•©ë‹ˆë‹¤","ë©ë‹ˆë‹¤","í•˜ëŠ”ë°","í•˜ë©´","í•´ì„œ","í•˜ì—¬","ëŒ€í•œ","ê´€ë ¨","í•„ìš”","ì¤‘ìš”","ìš°ì„ ","ì œê³µ"
    }

    doc_tokens = [tokenize_ko_basic(x, STOP) for x in open_s.tolist()]
    all_tokens = [t for toks in doc_tokens for t in toks]

    # (A) í‚¤ì›Œë“œ ë¹ˆë„
    st.subheader("ğŸ” ì „ì²´ ìƒìœ„ í‚¤ì›Œë“œ")
    top_n = st.slider("Top í‚¤ì›Œë“œ ê°œìˆ˜", 10, 80, 30, 5, key="edu_e4_topn")

    if not all_tokens:
        st.info("í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        freq = Counter(all_tokens)
        freq_df = pd.DataFrame(freq.most_common(top_n), columns=["keyword", "count"])
        fig_kw = px.bar(
            freq_df.sort_values("count", ascending=True),
            x="count", y="keyword",
            orientation="h",
            title=f"ì „ì²´ ìƒìœ„ {top_n}ê°œ í‚¤ì›Œë“œ"
        )
        fig_kw.update_layout(height=620, margin=dict(l=20, r=20, t=60, b=20),
                             xaxis_title="ë¹ˆë„", yaxis_title="í‚¤ì›Œë“œ")
        st.plotly_chart(fig_kw, use_container_width=True)
        st.dataframe(freq_df, use_container_width=True, hide_index=True)

    # (B) ê·¸ë£¹ë³„ í‚¤ì›Œë“œ ë¹„êµ
    st.subheader("ğŸ‘¥ ê·¸ë£¹ë³„ í‚¤ì›Œë“œ ë¹„êµ")
    group_col = st.selectbox("ê·¸ë£¹ ê¸°ì¤€ ì„ íƒ", ["Academic_Field", "Year_Level"], index=0, key="edu_e4_groupcol")
    min_n = st.slider("ê·¸ë£¹ ìµœì†Œ ì‘ë‹µ ìˆ˜", 1, 30, 5, key="edu_e4_min_group_n")

    tmp_df = fdf.copy()
    tmp_df["__open__"] = tmp_df[COL_E4].astype(str).map(clean_text)
    tmp_df = tmp_df[(tmp_df["__open__"] != "") & (~tmp_df["__open__"].map(is_no_response))]

    grp_counts = tmp_df.groupby(group_col)["__open__"].count().reset_index(name="N")
    valid_groups = grp_counts[grp_counts["N"] >= min_n][group_col].astype(str).tolist()

    if not valid_groups:
        st.info("í˜„ì¬ ì¡°ê±´ì—ì„œ ìµœì†Œ ì‘ë‹µ ìˆ˜ ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤. (ìµœì†Œ ì‘ë‹µ ìˆ˜ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.)")
    else:
        show_groups = st.multiselect(
            "í‘œì‹œí•  ê·¸ë£¹ ì„ íƒ",
            valid_groups,
            default=valid_groups[: min(6, len(valid_groups))],
            key="edu_e4_groups_pick"
        )
        per_top = st.slider("ê·¸ë£¹ë³„ Top í‚¤ì›Œë“œ ìˆ˜", 5, 30, 10, 1, key="edu_e4_per_top")

        rows = []
        for gname in show_groups:
            sub_text = tmp_df[tmp_df[group_col].astype(str) == str(gname)]["__open__"].tolist()
            toks = [t for text in sub_text for t in tokenize_ko_basic(text, STOP)]
            if not toks:
                continue
            for kw, ct in Counter(toks).most_common(per_top):
                rows.append({"Group": str(gname), "keyword": kw, "count": ct})

        if not rows:
            st.info("ì„ íƒí•œ ê·¸ë£¹ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            gkw = pd.DataFrame(rows)
            fig_gkw = px.bar(
                gkw,
                x="count",
                y="keyword",
                color="Group",
                orientation="h",
                title=f"{group_col}ë³„ ìƒìœ„ í‚¤ì›Œë“œ ë¹„êµ (Top {per_top})"
            )
            fig_gkw.update_layout(height=700, margin=dict(l=20, r=20, t=60, b=20),
                                  xaxis_title="ë¹ˆë„", yaxis_title="í‚¤ì›Œë“œ")
            st.plotly_chart(fig_gkw, use_container_width=True)
            st.dataframe(gkw.sort_values(["Group", "count"], ascending=[True, False]),
                         use_container_width=True, hide_index=True)

    # (C) ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬(Plotly)
    st.subheader("ğŸ•¸ï¸ í‚¤ì›Œë“œ ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬")
    st.caption("í•œ ì‘ë‹µ ì•ˆì—ì„œ í•¨ê»˜ ë“±ì¥í•œ í‚¤ì›Œë“œ ìŒì„ ì—°ê²°í•©ë‹ˆë‹¤. (ìƒìœ„ í‚¤ì›Œë“œ ì¤‘ì‹¬)")

    net_top = st.slider("ë„¤íŠ¸ì›Œí¬ì— í¬í•¨í•  ìƒìœ„ í‚¤ì›Œë“œ ìˆ˜", 10, 120, 40, 5, key="edu_e4_net_top")
    min_edge = st.slider("ì—£ì§€ ìµœì†Œ ê³µë™ì¶œí˜„ íšŸìˆ˜", 1, 20, 2, 1, key="edu_e4_net_min_edge")

    if not all_tokens:
        st.info("ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“¤ í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        top_vocab = [k for k, _ in Counter(all_tokens).most_common(net_top)]
        vocab_set = set(top_vocab)

        pair_counter = Counter()
        for toks in doc_tokens:
            uniq = [t for t in set(toks) if t in vocab_set]
            uniq.sort()
            for i in range(len(uniq)):
                for j in range(i + 1, len(uniq)):
                    pair_counter[(uniq[i], uniq[j])] += 1

        edges = [(a, b, w) for (a, b), w in pair_counter.items() if w >= min_edge]

        if not edges:
            st.info("í˜„ì¬ ì„¤ì •(min_edge ë“±)ì—ì„œ ë„¤íŠ¸ì›Œí¬ ì—£ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì—£ì§€ ìµœì†Œ ê³µë™ì¶œí˜„ íšŸìˆ˜ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.")
        else:
            import numpy as np

            node_w = {k: Counter(all_tokens)[k] for k in top_vocab}

            n = len(top_vocab)
            angles = np.linspace(0, 2*np.pi, n, endpoint=False)
            pos = {top_vocab[i]: (np.cos(angles[i]), np.sin(angles[i])) for i in range(n)}

            edge_x, edge_y = [], []
            for a, b, w in edges:
                x0, y0 = pos[a]
                x1, y1 = pos[b]
                edge_x += [x0, x1, None]
                edge_y += [y0, y1, None]

            edge_trace = go.Scatter(
                x=edge_x, y=edge_y,
                mode="lines",
                hoverinfo="none",
                line=dict(width=1),
                name="co-occurrence"
            )

            node_x = [pos[k][0] for k in top_vocab]
            node_y = [pos[k][1] for k in top_vocab]
            node_size = [max(10, min(38, node_w[k])) for k in top_vocab]
            node_text = [f"{k} (freq={node_w[k]})" for k in top_vocab]

            node_trace = go.Scatter(
                x=node_x, y=node_y,
                mode="markers+text",
                text=top_vocab,
                textposition="top center",
                hovertext=node_text,
                hoverinfo="text",
                marker=dict(size=node_size),
                name="keywords"
            )

            fig_net = go.Figure(data=[edge_trace, node_trace])
            fig_net.update_layout(
                title="í‚¤ì›Œë“œ ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬ (ì›í˜• ë°°ì¹˜)",
                showlegend=False,
                height=760,
                margin=dict(l=10, r=10, t=60, b=10),
                xaxis=dict(visible=False),
                yaxis=dict(visible=False)
            )
            st.plotly_chart(fig_net, use_container_width=True)

            edge_df = pd.DataFrame(edges, columns=["keyword_a", "keyword_b", "cooccur"])
            edge_df = edge_df.sort_values("cooccur", ascending=False).head(200)
            st.subheader("ê³µë™ì¶œí˜„ ìƒìœ„ ì—£ì§€(Top 200)")
            st.dataframe(edge_df, use_container_width=True, hide_index=True)

    # (D) ì›Œë“œí´ë¼ìš°ë“œ(ê°€ëŠ¥í•œ ê²½ìš°)
    st.subheader("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ (ê°€ëŠ¥í•œ ê²½ìš°)")
    st.caption("ì„œë²„ì— wordcloud íŒ¨í‚¤ì§€ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ê±´ë„ˆëœë‹ˆë‹¤. í•œê¸€ í°íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    try:
        from wordcloud import WordCloud
        import matplotlib.pyplot as plt

        # âœ… ë ˆí¬ì— assets í´ë”ê°€ ìˆê³ , í°íŠ¸ê°€ ë“¤ì–´ìˆë‹¤ëŠ” ì „ì œ
        font_path = "assets/NanumGothic-Regular.ttf"

        if not all_tokens:
            st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ë§Œë“¤ í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            freq_dict = dict(Counter(all_tokens))
            wc = WordCloud(
                font_path=font_path,
                width=1400,
                height=650,
                background_color="white",
                prefer_horizontal=0.9
            ).generate_from_frequencies(freq_dict)

            fig, ax = plt.subplots(figsize=(14, 6.5))
            ax.imshow(wc, interpolation="bilinear")
            ax.axis("off")
            st.pyplot(fig, clear_figure=True)

    except ModuleNotFoundError:
        st.info("wordcloud íŒ¨í‚¤ì§€ê°€ ì—†ì–´ ì›Œë“œí´ë¼ìš°ë“œë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. requirements.txtì— wordcloudë¥¼ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤.")
    except FileNotFoundError:
        st.error("í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. assets/NanumGothic-Regular.ttf ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

