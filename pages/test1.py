import re
from collections import Counter

import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

# =========================================
# Education(ì‚¬ë²”) E-items (E1~E4)
# - E1~E3: ë³µìˆ˜ì„ íƒ(ì˜µì…˜í˜•)
# - E4: ì£¼ê´€ì‹
# =========================================
st.set_page_config(page_title="Education E-items (E1â€“E4)", layout="wide")

CSV_URL_EDU = "https://raw.githubusercontent.com/MK316/camp26/refs/heads/main/data/Edu-essay123.csv"

# =========================
# Columns (actual CSV)
# =========================
META_COLS = ["Academic_Field", "Year_Level", "Year_Original"]

COL_E1 = "E1"
COL_E2 = "E2"
COL_E3 = "E3"
COL_E4 = "E4"

E_MULTI = [COL_E1, COL_E2, COL_E3]
E_OPEN = COL_E4

# =========================
# Display labels (shown on screen)
# =========================
DISPLAY_LABELS = {
    COL_E1: "E1. [êµìœ¡ê³¼ì •Â·ì •ì±… ê°œì„  ìš”êµ¬]",
    COL_E2: "E2. [ì •ì„œì  ë¶€ë‹´ê°ì˜ ì›ì¸]",
    COL_E3: "E3. [í•™ìŠµ ë‚´ìš© ì„ í˜¸]",
    COL_E4: "E4. [ì£¼ê´€ì‹: ììœ ë¡­ê²Œ ê¸°ìˆ ]",
    "Academic_Field": "í•™ë¬¸ ë¶„ì•¼ (Academic_Field)",
    "Year_Level": "í•™ë…„ (Year_Level)",
    "Year_Original": "ì› í•™ë…„ í‘œê¸° (Year_Original)",
}

# =========================================
# (ì„ íƒ) ì˜µì…˜ ëª©ë¡ ê³ ì •(ì›í•˜ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë„£ê¸°)
# - Noneì´ë©´ ë°ì´í„°ì—ì„œ ìë™ ì¶”ì¶œ(ê¶Œì¥: ìš°ì„  ìë™)
# =========================================
E1_OPTIONS = None
E2_OPTIONS = None
E3_OPTIONS = None

OPTIONS_MAP = {
    COL_E1: E1_OPTIONS,
    COL_E2: E2_OPTIONS,
    COL_E3: E3_OPTIONS,
}

# =========================================
# Helpers
# =========================================
@st.cache_data(show_spinner=False)
def load_data(url: str) -> pd.DataFrame:
    try:
        df = pd.read_csv(url, encoding="utf-8")
    except UnicodeDecodeError:
        df = pd.read_csv(url, encoding="cp949")

    # ë¬¸ìì—´ ê³µë°± ì œê±°
    for c in df.columns:
        if df[c].dtype == object:
            df[c] = df[c].astype(str).str.strip()

    # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬ (E1~E4ê°€ ì´ë¯¸ ì¡´ì¬í•´ì•¼ í•¨)
    required = META_COLS + [COL_E1, COL_E2, COL_E3, COL_E4]
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error("CSVì— ë‹¤ìŒ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤:\n\n- " + "\n- ".join(missing))
        st.stop()

    return df


def clean_text(s: str) -> str:
    if not isinstance(s, str):
        return ""
    return re.sub(r"\s+", " ", s).strip()


def is_no_response(text: str) -> bool:
    t = clean_text(str(text)).lower()
    if t in {"", "nan", "none"}:
        return True
    return t in {"no response", "noresponse", "n/a", "na"}


def split_multiselect(text: str) -> list[str]:
    """
    ë³µìˆ˜ì„ íƒ ì‘ë‹µ íŒŒì‹±:
    - êµ¬ë¶„ì: ; , / | ì¤„ë°”ê¿ˆ
    """
    t = clean_text(text)
    if not t or is_no_response(t):
        return []
    t = t.replace("\n", ";").replace("â€¢", ";")
    parts = re.split(r"[;,/|]+", t)
    return [p.strip() for p in parts if p.strip()]


def multiselect_summary(df: pd.DataFrame, col: str, option_order: list[str] | None) -> tuple[pd.DataFrame, int]:
    base = df[[col]].copy()
    base["__rid__"] = base.index
    base["choices"] = base[col].apply(split_multiselect)

    n_resp = int((base["choices"].apply(len) > 0).sum())
    if n_resp == 0:
        out0 = pd.DataFrame({"ì˜µì…˜": (option_order or []), "ì‘ë‹µììˆ˜": 0, "ì‘ë‹µìë¹„ìœ¨(%)": 0.0})
        return out0, 0

    ex = base.explode("choices").dropna(subset=["choices"])
    ex["choices"] = ex["choices"].astype(str).str.strip()
    ex = ex[ex["choices"] != ""]

    # ì˜µì…˜ ëª©ë¡ ê³ ì •ì´ ìˆìœ¼ë©´, ì˜µì…˜ ì™¸ëŠ” 'ê¸°íƒ€'ë¡œ í¡ìˆ˜
    if option_order:
        allowed = set(option_order)
        ex.loc[~ex["choices"].isin(allowed), "choices"] = "ê¸°íƒ€"
        if "ê¸°íƒ€" not in allowed:
            option_order = option_order + ["ê¸°íƒ€"]

    grp = ex.drop_duplicates(subset=["__rid__", "choices"]).groupby("choices")["__rid__"].nunique()

    # ìë™(ë°ì´í„° ê¸°ë°˜)ì¼ ë•ŒëŠ” ë¹ˆë„ ìˆœìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ
    if option_order is None:
        options = grp.sort_values(ascending=False).index.tolist()
    else:
        options = option_order

    out = pd.DataFrame({"ì˜µì…˜": options})
    out["ì‘ë‹µììˆ˜"] = out["ì˜µì…˜"].map(grp).fillna(0).astype(int)
    out["ì‘ë‹µìë¹„ìœ¨(%)"] = (out["ì‘ë‹µììˆ˜"] / n_resp * 100).round(2)

    # âœ… ë§ì€ ë¹ˆë„ ë¨¼ì €
    out = out.sort_values(["ì‘ë‹µììˆ˜", "ì˜µì…˜"], ascending=[False, True]).reset_index(drop=True)
    return out, n_resp


def tokenize_ko_basic(text: str, stop: set[str]) -> list[str]:
    t = re.sub(r"[^0-9A-Za-zê°€-í£\s]", " ", str(text))
    t = re.sub(r"\s+", " ", t).strip()
    if not t:
        return []
    toks = []
    for w in t.split(" "):
        if len(w) < 2:
            continue
        if w in stop:
            continue
        toks.append(w)
    return toks


# =========================================
# UI
# =========================================
st.markdown("### ğŸ§© ì‚¬ë²”(Education) ì˜ì—­: E1â€“E4")
st.caption("E1â€“E3: ë³µìˆ˜ì„ íƒ(ì‘ë‹µì ê¸°ì¤€ %), E4: ì£¼ê´€ì‹(í‚¤ì›Œë“œ/ê·¸ë£¹ ë¹„êµ/ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬ + ì›Œë“œí´ë¼ìš°ë“œ(ê°€ëŠ¥ ì‹œ))")

df = load_data(CSV_URL_EDU)

with st.sidebar:
    st.header("í•„í„° (Filters)")

    all_af = sorted(df["Academic_Field"].dropna().astype(str).unique().tolist())
    af = st.multiselect("í•™ë¬¸ ë¶„ì•¼ (Academic_Field)", all_af, default=all_af)

    all_yl = sorted(df["Year_Level"].dropna().astype(str).unique().tolist())
    yl = st.multiselect("í•™ë…„ (Year_Level)", all_yl, default=all_yl)

    all_yo = sorted(df["Year_Original"].dropna().astype(str).unique().tolist())
    yo = st.multiselect("ì› í•™ë…„ í‘œê¸° (Year_Original)", all_yo, default=all_yo)

    st.divider()
    palette = st.selectbox(
        "ìƒ‰ìƒ íŒ”ë ˆíŠ¸ (Bar ê³µí†µ)",
        ["Plotly", "D3", "G10", "T10", "Alphabet", "Dark24", "Set2", "Pastel"],
        index=0,
    )
    show_raw = st.checkbox("ì›ìë£Œ ì¼ë¶€ ë³´ê¸°", value=False)

fdf = df[
    df["Academic_Field"].isin(af) &
    df["Year_Level"].isin(yl) &
    df["Year_Original"].isin(yo)
].copy()

c1, c2, c3 = st.columns(3)
c1.metric("í‘œë³¸ ìˆ˜ (í˜„ì¬ í•„í„° N)", f"{len(fdf):,}")
c2.metric("ì„ íƒ Academic_Field ìˆ˜", f"{len(af):,}")
c3.metric("ì„ íƒ Year_Level ìˆ˜", f"{len(yl):,}")

if show_raw:
    st.subheader("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    show_cols = META_COLS + [COL_E1, COL_E2, COL_E3, COL_E4]
    st.dataframe(fdf[show_cols].rename(columns=DISPLAY_LABELS).head(30), use_container_width=True)

tab1, tab2, tab3, tab4 = st.tabs([
    DISPLAY_LABELS[COL_E1],
    DISPLAY_LABELS[COL_E2],
    DISPLAY_LABELS[COL_E3],
    DISPLAY_LABELS[COL_E4],
])

# íŒ”ë ˆíŠ¸ -> ìƒ‰ìƒ ì‹œí€€ìŠ¤
color_seq = getattr(px.colors.qualitative, palette, px.colors.qualitative.Plotly)


def render_multi(col: str, option_order: list[str] | None):
    st.markdown(f"#### {DISPLAY_LABELS.get(col, col)}")
    st.caption("ë³µìˆ˜ì„ íƒ ë¬¸í•­ì…ë‹ˆë‹¤. ê·¸ë˜í”„ëŠ” â€˜ì‘ë‹µì ê¸°ì¤€ ë¹„ìœ¨(%)â€™ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.")

    summ, n_resp = multiselect_summary(fdf, col, option_order)
    st.metric("í•´ë‹¹ ë¬¸í•­ ì‘ë‹µì ìˆ˜ (N)", f"{n_resp:,}")

    if n_resp == 0:
        st.info("í˜„ì¬ í•„í„° ì¡°ê±´ì—ì„œ ìœ íš¨ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í•­ëª©ë³„ ìƒ‰(íŒ”ë ˆíŠ¸ ì ìš©)
    opts = summ["ì˜µì…˜"].tolist()
    cmap = {opt: color_seq[i % len(color_seq)] for i, opt in enumerate(opts)}

    # ê°€ë¡œë§‰ëŒ€: ìœ„ìª½ì— í° ê°’
    plot_df = summ.sort_values("ì‘ë‹µìë¹„ìœ¨(%)", ascending=True)

    fig = px.bar(
        plot_df,
        x="ì‘ë‹µìë¹„ìœ¨(%)",
        y="ì˜µì…˜",
        orientation="h",
        text="ì‘ë‹µìë¹„ìœ¨(%)",
        color="ì˜µì…˜",
        color_discrete_map=cmap,
        title="ì„ íƒ ë¹„ìœ¨ (ì‘ë‹µì ê¸°ì¤€ %)"
    )
    fig.update_traces(texttemplate="%{text:.1f}%", textposition="outside", cliponaxis=False)
    fig.update_layout(
        height=560,
        showlegend=False,
        margin=dict(l=10, r=10, t=60, b=10),
        xaxis_title="ì‘ë‹µì ë¹„ìœ¨(%)",
        yaxis_title=""
    )
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("ì˜µì…˜ë³„ ë¹ˆë„í‘œ")
    st.dataframe(summ, use_container_width=True, hide_index=True)


with tab1:
    render_multi(COL_E1, OPTIONS_MAP[COL_E1])

with tab2:
    render_multi(COL_E2, OPTIONS_MAP[COL_E2])

with tab3:
    render_multi(COL_E3, OPTIONS_MAP[COL_E3])

with tab4:
    st.markdown(f"#### {DISPLAY_LABELS.get(COL_E4, COL_E4)}")
    st.caption("ì£¼ê´€ì‹ ë¬¸í•­ì…ë‹ˆë‹¤. 'No Response'ëŠ” ì œì™¸ë©ë‹ˆë‹¤. ì•„ë˜ëŠ” í‚¤ì›Œë“œ ë¹ˆë„, ê·¸ë£¹ë³„ ë¹„êµ, ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬, ì›Œë“œí´ë¼ìš°ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤.")

    open_s = fdf[COL_E4].astype(str).map(clean_text)
    open_s = open_s[(open_s != "") & (~open_s.map(is_no_response))]

    st.metric("ì£¼ê´€ì‹ ì‘ë‹µ ìˆ˜ (N)", f"{len(open_s):,}")
    if open_s.empty:
        st.warning("í˜„ì¬ í•„í„° ì¡°ê±´ì—ì„œ E4 ì£¼ê´€ì‹ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    STOP = {
        "ê·¸ë¦¬ê³ ","í•˜ì§€ë§Œ","ë˜í•œ","ê·¸ë˜ì„œ","ë•Œë¬¸","ì •ë„","ê°™ì•„ìš”","í•©ë‹ˆë‹¤","í–ˆë‹¤","í•˜ëŠ”","ì—ì„œ","ìœ¼ë¡œ","ì—ê²Œ",
        "ê²ƒ","ìˆ˜","ë“±","ì¢€","ë”","ì œ","ì €","ìš°ë¦¬","ë„ˆë¬´","ì •ë§","ìˆë‹¤","ì—†ë‹¤","ì´ë‹¤","ë˜ë‹¤","ìˆëŠ”",
        "í•©ë‹ˆë‹¤","ë©ë‹ˆë‹¤","í•˜ëŠ”ë°","í•˜ë©´","í•´ì„œ","í•˜ì—¬","ëŒ€í•œ","ê´€ë ¨","í•„ìš”","ì¤‘ìš”","ìš°ì„ ","ì œê³µ"
    }

    doc_tokens = [tokenize_ko_basic(x, STOP) for x in open_s.tolist()]
    all_tokens = [t for toks in doc_tokens for t in toks]

    # (A) í‚¤ì›Œë“œ ë¹ˆë„
    st.subheader("ğŸ” ì „ì²´ ìƒìœ„ í‚¤ì›Œë“œ")
    top_n = st.slider("Top í‚¤ì›Œë“œ ê°œìˆ˜", 10, 120, 40, 5, key="edu_e4_topn")

    if not all_tokens:
        st.info("í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•  í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        freq = Counter(all_tokens)
        freq_df = pd.DataFrame(freq.most_common(top_n), columns=["keyword", "count"])
        fig_kw = px.bar(
            freq_df.sort_values("count", ascending=True),
            x="count", y="keyword",
            orientation="h",
            title=f"ì „ì²´ ìƒìœ„ {top_n}ê°œ í‚¤ì›Œë“œ"
        )
        fig_kw.update_layout(height=680, margin=dict(l=20, r=20, t=60, b=20),
                             xaxis_title="ë¹ˆë„", yaxis_title="í‚¤ì›Œë“œ")
        st.plotly_chart(fig_kw, use_container_width=True)
        st.dataframe(freq_df, use_container_width=True, hide_index=True)

    # (B) ê·¸ë£¹ë³„ í‚¤ì›Œë“œ ë¹„êµ
    st.subheader("ğŸ‘¥ ê·¸ë£¹ë³„ í‚¤ì›Œë“œ ë¹„êµ")
    group_col = st.selectbox("ê·¸ë£¹ ê¸°ì¤€ ì„ íƒ", ["Academic_Field", "Year_Level", "Year_Original"], index=0, key="edu_e4_groupcol")
    min_n = st.slider("ê·¸ë£¹ ìµœì†Œ ì‘ë‹µ ìˆ˜", 1, 30, 5, key="edu_e4_min_group_n")

    tmp_df = fdf.copy()
    tmp_df["__open__"] = tmp_df[COL_E4].astype(str).map(clean_text)
    tmp_df = tmp_df[(tmp_df["__open__"] != "") & (~tmp_df["__open__"].map(is_no_response))]

    grp_counts = tmp_df.groupby(group_col)["__open__"].count().reset_index(name="N")
    valid_groups = grp_counts[grp_counts["N"] >= min_n][group_col].astype(str).tolist()

    if not valid_groups:
        st.info("í˜„ì¬ ì¡°ê±´ì—ì„œ ìµœì†Œ ì‘ë‹µ ìˆ˜ ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤. (ìµœì†Œ ì‘ë‹µ ìˆ˜ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.)")
    else:
        show_groups = st.multiselect(
            "í‘œì‹œí•  ê·¸ë£¹ ì„ íƒ",
            valid_groups,
            default=valid_groups[: min(6, len(valid_groups))],
            key="edu_e4_groups_pick"
        )
        per_top = st.slider("ê·¸ë£¹ë³„ Top í‚¤ì›Œë“œ ìˆ˜", 5, 40, 12, 1, key="edu_e4_per_top")

        rows = []
        for gname in show_groups:
            sub_text = tmp_df[tmp_df[group_col].astype(str) == str(gname)]["__open__"].tolist()
            toks = [t for text in sub_text for t in tokenize_ko_basic(text, STOP)]
            if not toks:
                continue
            for kw, ct in Counter(toks).most_common(per_top):
                rows.append({"Group": str(gname), "keyword": kw, "count": ct})

        if not rows:
            st.info("ì„ íƒí•œ ê·¸ë£¹ì—ì„œ ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            gkw = pd.DataFrame(rows)
            fig_gkw = px.bar(
                gkw,
                x="count",
                y="keyword",
                color="Group",
                orientation="h",
                title=f"{group_col}ë³„ ìƒìœ„ í‚¤ì›Œë“œ ë¹„êµ (Top {per_top})"
            )
            fig_gkw.update_layout(height=740, margin=dict(l=20, r=20, t=60, b=20),
                                  xaxis_title="ë¹ˆë„", yaxis_title="í‚¤ì›Œë“œ")
            st.plotly_chart(fig_gkw, use_container_width=True)
            st.dataframe(gkw.sort_values(["Group", "count"], ascending=[True, False]),
                         use_container_width=True, hide_index=True)

    # (C) ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬
    st.subheader("ğŸ•¸ï¸ í‚¤ì›Œë“œ ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬")
    st.caption("í•œ ì‘ë‹µ ì•ˆì—ì„œ í•¨ê»˜ ë“±ì¥í•œ í‚¤ì›Œë“œ ìŒì„ ì—°ê²°í•©ë‹ˆë‹¤. (ìƒìœ„ í‚¤ì›Œë“œ ì¤‘ì‹¬)")

    net_top = st.slider("ë„¤íŠ¸ì›Œí¬ì— í¬í•¨í•  ìƒìœ„ í‚¤ì›Œë“œ ìˆ˜", 10, 150, 50, 5, key="edu_e4_net_top")
    min_edge = st.slider("ì—£ì§€ ìµœì†Œ ê³µë™ì¶œí˜„ íšŸìˆ˜", 1, 20, 2, 1, key="edu_e4_net_min_edge")

    if not all_tokens:
        st.info("ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“¤ í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        import numpy as np

        top_vocab = [k for k, _ in Counter(all_tokens).most_common(net_top)]
        vocab_set = set(top_vocab)

        pair_counter = Counter()
        for toks in doc_tokens:
            uniq = [t for t in set(toks) if t in vocab_set]
            uniq.sort()
            for i in range(len(uniq)):
                for j in range(i + 1, len(uniq)):
                    pair_counter[(uniq[i], uniq[j])] += 1

        edges = [(a, b, w) for (a, b), w in pair_counter.items() if w >= min_edge]

        if not edges:
            st.info("í˜„ì¬ ì„¤ì •(min_edge ë“±)ì—ì„œ ë„¤íŠ¸ì›Œí¬ ì—£ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì—£ì§€ ìµœì†Œ ê³µë™ì¶œí˜„ íšŸìˆ˜ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.")
        else:
            node_w = {k: Counter(all_tokens)[k] for k in top_vocab}

            n = len(top_vocab)
            angles = np.linspace(0, 2*np.pi, n, endpoint=False)
            pos = {top_vocab[i]: (np.cos(angles[i]), np.sin(angles[i])) for i in range(n)}

            edge_x, edge_y = [], []
            for a, b, w in edges:
                x0, y0 = pos[a]
                x1, y1 = pos[b]
                edge_x += [x0, x1, None]
                edge_y += [y0, y1, None]

            edge_trace = go.Scatter(
                x=edge_x, y=edge_y,
                mode="lines",
                hoverinfo="none",
                line=dict(width=1),
                name="co-occurrence"
            )

            node_x = [pos[k][0] for k in top_vocab]
            node_y = [pos[k][1] for k in top_vocab]
            node_size = [max(10, min(38, node_w[k])) for k in top_vocab]
            node_text = [f"{k} (freq={node_w[k]})" for k in top_vocab]

            node_trace = go.Scatter(
                x=node_x, y=node_y,
                mode="markers+text",
                text=top_vocab,
                textposition="top center",
                hovertext=node_text,
                hoverinfo="text",
                marker=dict(size=node_size),
                name="keywords"
            )

            fig_net = go.Figure(data=[edge_trace, node_trace])
            fig_net.update_layout(
                title="í‚¤ì›Œë“œ ê³µë™ì¶œí˜„ ë„¤íŠ¸ì›Œí¬ (ì›í˜• ë°°ì¹˜)",
                showlegend=False,
                height=780,
                margin=dict(l=10, r=10, t=60, b=10),
                xaxis=dict(visible=False),
                yaxis=dict(visible=False)
            )
            st.plotly_chart(fig_net, use_container_width=True)

            edge_df = pd.DataFrame(edges, columns=["keyword_a", "keyword_b", "cooccur"])
            edge_df = edge_df.sort_values("cooccur", ascending=False).head(200)
            st.subheader("ê³µë™ì¶œí˜„ ìƒìœ„ ì—£ì§€(Top 200)")
            st.dataframe(edge_df, use_container_width=True, hide_index=True)

    # (D) ì›Œë“œí´ë¼ìš°ë“œ (ê°€ëŠ¥í•œ ê²½ìš°)
    st.subheader("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ (ê°€ëŠ¥í•œ ê²½ìš°)")
    st.caption("ì„œë²„ì— wordcloud íŒ¨í‚¤ì§€ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ê±´ë„ˆëœë‹ˆë‹¤. í•œê¸€ í°íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    try:
        from wordcloud import WordCloud
        import matplotlib.pyplot as plt

        font_path = "assets/NanumGothic-Regular.ttf"

        if not all_tokens:
            st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ë§Œë“¤ í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            freq_dict = dict(Counter(all_tokens))
            wc = WordCloud(
                font_path=font_path,
                width=1400,
                height=650,
                background_color="white",
                prefer_horizontal=0.9
            ).generate_from_frequencies(freq_dict)

            fig, ax = plt.subplots(figsize=(14, 6.5))
            ax.imshow(wc, interpolation="bilinear")
            ax.axis("off")
            st.pyplot(fig, clear_figure=True)

    except ModuleNotFoundError:
        st.info("wordcloud íŒ¨í‚¤ì§€ê°€ ì—†ì–´ ì›Œë“œí´ë¼ìš°ë“œë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. requirements.txtì— wordcloudë¥¼ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤.")
    except FileNotFoundError:
        st.error("í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. assets/NanumGothic-Regular.ttf ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        st.warning(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
